<!DOCTYPE html>
<html>
<head>
    <title>
        Performance Bible
    </title>
    <link rel="stylesheet" type="text/css" href="main.css">
</head>
<body>
    <h1>Performance Bible</h1>
    <p id=mainpara>Over the course of my career, I have scoured over many blog
        posts, forums and best practice guides to find ways to optimize
        performance of an OS or hypervisor. This is an effort to collect all of
        this in one place. Hopefully it is useful. I have tried to provide the
        reference source of every optimization. <br>
        Choose the platform and area of interest to look at
        recommended performance optimization options. <br>
    </p>
    <div class='main_section'>
        <div class='select_section'>
            Platform : <select id=hyperselect name=hypervisor>
                <option value='vsphere60' selected>vSphere 6.0</option>
                <option value='vsphere55'>vSphere 5.5</option>
                <option value='centos'>Centos Linux</option>
            </select> <br>
            Sections :  <select id=areaselect name=areas>
                <option value='hardware'>Hardware Performance Optimizations</option>
                <option value='storage'>Storage Performance Optimizations</option>
                <option value='network'>Network Performance Optimizations</option>
                <option value='general' selected>General Performance Optimizations</option></select>
                <button type="button" onclick="selectArea(areaselect.value, hyperselect.value)">Go</button>
        </div>
        <div class='vsphere60' id=hyper1>
            <div id=vsphere60hardware>
                <table class=table60 id=table60hardware>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Intel VT-x or AMD-V</td>
                        <td>Hardware assisted CPU virtualization assistance</td>
                        <td>Reboot host, Enter BIOS, Enable VT-x or AMD-V</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Hyper Threading</td>
                        <td>Allows single processor to behave like two logical processors. Can run two independent threads simultaneously</td>
                        <td>Reboot host, Enter BIOS, Enable HT</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Turbo Boost</td>
                        <td></td>
                        <td>Reboot host, Enter BIOS, Enable Turbo Boost</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>NUMA</td>
                        <td>Non Uniform Memory Access</td>
                        <td>Reboot host, Enter BIOS, Enable NUMA</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Power Management</td>
                        <td>vSphere has power management built in. Change the BIOS to set the power management to OS Controlled to take advantage of vSphere power management. Advantage is that it can be easily configured in command line</td>
                        <td>Reboot host, Enter BIOS, Select power management -> OS Controlled</td>
                        <td>OS Controlled</td>
                    </tr>
                    <tr>
                        <td>C States</td>
                        <td>vSphere power management has c states control built in. Enable all c states in BIOS to be able to control them using vSphere</td>
                        <td>Reboot host, Enter BIOS, Enable C States</td>
                        <td>Enable</td>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 hardware content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=vsphere60storage>
                <table class=table60 id=table60storage>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Net.TcpipHeapMax</td>
                        <td>Max heap that can be used for TCP IP. Benefits when number of NFS luns is high. Size in MB</td>
                        <td>esxcfg-advcfg /Net/TcpipHeapMax -s 1536</td>
                        <td>1536</td>
                    </tr>
                    <tr>
                        <td>FC HBA Queue Depth</td>
                        <td>Increase the Max Queue Depth on the HBA to handle more IO</td>
                        <td>QLogic: esxcli system module parameters set -p ql2xmaxqdepth=128 -m qla2xxx;
                        Emulex: esxcli system module parameters set -p lpfc0_lun_queue_depth=128 -m lpfc820;
                        Brocade: esxcli system module parameters set -p bfa_lun_queue_depth=128 -m bfa;</td>
                        <td>128</td>
                    </tr>
                    <tr>
                        <td>Partition Alignment</td>
                        <td>VMFS partition alignment makes a difference in performance</td>
                        <td>Use vSphere Client to create a vmfs partition. If using CLI, create partition using storage vendor recommendation. If no recommendation is present, use starting block address that is a multiple of 8KB</td>
                        <td>Align Partition</td>
                    </tr>
                    <tr>
                        <td>
                            SIOC
                        </td>
                        <td>
                            Enables datastore resource sharing among VMS. Can be benefitial when there are many VMs sharing a single datastore.
                        </td>
                        <td>
                            vSphere Client -> Datastore -> Configuration -> Properties -> SIOC -> Enable
                        </td>
                        <td>
                            Enable when VM / datastore ratio is high
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Jumbo Frames
                        </td>
                        <td>
                            MTU > 1500 is Jumbo. Enable Jumbo Frames to reduce CPU processing overhead with iSCSI (SW/HW). End to end support and enabling is required. On vSphere, Enable Jumbo Frames in virtual switches (SWiSCSI) and storage adapter (HWiSCSI)
                        </td>
                        <td>
                            Manage -> Networking -> Virtual Switches -> Settings -> Properties -> MTU;
                            Manage -> Storage -> Storage Adapters -> Advanced Options -> Edit -> MTU
                        </td>
                        <td>
                            Enable Jumbo Frames End to End
                        </td>
                    </tr>
                    <tr>
                        <td>
                            VLAN
                        </td>
                        <td>
                            Create VLAN for vmknic and iSCSI/NFS Server. Having separate VLAN helps reduce network interference
                        </td>
                        <td>

                        </td>
                        <td>
                            Create VLAN
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Keep VMs/LUNs ratio low
                        </td>
                        <td>
                            Provisioning more LUNs and keeping the VMs on these LUNs low helps present I/Os simultaneously to the array increasing performance. Use ESXTOP to monitor Device latencies and provision accordingly.
                        </td>
                        <td>
                            Follow storage vendor recommendations
                        </td>
                        <td>
                            Provision more LUNs for spreading the I/O load.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Use ESXTOP
                        </td>
                        <td>
                            esxtop can be used to troubleshoot storage performance problems. It provides a starting point to root cause a storage performance issue
                        </td>
                        <td>
                            Use vSphere kb article No 1008205
                            Use Yellow Bricks ESXTOP article <a href='http://www.yellow-bricks.com/esxtop/'>Yellow Bricks</a>
                        </td>
                        <td>
                            Use esxtop for troubleshooting storage issues
                        </td>
                    </tr>
                    <tr>
                        <td>
                            vHBA reqCallThreshold
                        </td>
                        <td>
                            If using LSILogic vHBA or PVSCSI vHBA for VMs, you can set a lower threshold value. If set to 1, even if there is 1 I/O in the vHBA layer, it will be dispatched to the lower layer
                        </td>
                        <td>
                            esxcfg-advcfg -s X /Disk/ReqCallThreshold
                            You can also set this in a vmx file using the following command
                            scsiY.reqCallThreshold = X (where Y is the target SCSI number and X is the desired reqCallThreshold value
                        </td>
                        <td>
                            Lower the reqCallThreshold for latency sensitive applications
                        </td>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 storage content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=vsphere60network>
                <table class=table60 id=table60network>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Net.TcpipHeapMax</td>
                        <td></td>
                        <td>esxcfg-advcfg /Net/TcpipHeapMax -s 1536</td>
                        <td>1536</td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 network content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=vsphere60general>
                <table class=table60 id=table60general>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>vSphere Power Management</td>
                        <td>Set this to high performance setting to get max hardware performance. Pre-Requisite is BIOS - OS Control Mode</td>
                        <td>vsish -e set /power/currentPolicy 1</td>
                        <td>1</td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 general content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
        </div>
        <div class='vsphere55' id=hyper2>
            <div id=vsphere55hardware>
                <table class=table55 id=table55hardware>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Intel VT-x or AMD-V</td>
                        <td>Hardware assisted CPU virtualization assistance</td>
                        <td>Reboot host, Enter BIOS, Enable VT-x or AMD-V</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Hyper Threading</td>
                        <td>Allows single processor to behave like two logical processors. Can run two independent threads simultaneously</td>
                        <td>Reboot host, Enter BIOS, Enable HT</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Turbo Boost</td>
                        <td></td>
                        <td>Reboot host, Enter BIOS, Enable Turbo Boost</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>NUMA</td>
                        <td>Non Uniform Memory Access</td>
                        <td>Reboot host, Enter BIOS, Enable NUMA</td>
                        <td>Enable</td>
                    </tr>
                    <tr>
                        <td>Power Management</td>
                        <td>vSphere has power management built in. Change the BIOS to set the power management to OS Controlled to take advantage of vSphere power management. Advantage is that it can be easily configured in command line</td>
                        <td>Reboot host, Enter BIOS, Select power management -> OS Controlled</td>
                        <td>OS Controlled</td>
                    </tr>
                    <tr>
                        <td>C States</td>
                        <td>vSphere power management has c states control built in. Enable all c states in BIOS to be able to control them using vSphere</td>
                        <td>Reboot host, Enter BIOS, Enable C States</td>
                        <td>Enable</td>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 55 hardware content -->
            </div>
            <div id=vsphere55storage>
                <table class=table55 id=table55storage>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Net.TcpipHeapMax</td>
                        <td>Max heap that can be used for TCP IP. Benefits when number of NFS luns is high. Size in MB</td>
                        <td>esxcfg-advcfg /Net/TcpipHeapMax -s 512</td>
                        <td>512</td>
                    </tr>
                    <tr>
                        <td>FC HBA Queue Depth</td>
                        <td>Increase the Max Queue Depth on the HBA to handle more IO</td>
                        <td>QLogic: esxcli system module parameters set -p ql2xmaxqdepth=128 -m qlnativefc;
                        Emulex: esxcli system module parameters set -p lpfc0_lun_queue_depth=128 -m lpfc;</td>
                        <td>128</td>
                    </tr>
                    <tr>
                        <td>Partition Alignment</td>
                        <td>VMFS partition alignment makes a difference in performance</td>
                        <td>Use vSphere Client to create a vmfs partition. If using CLI, create partition using storage vendor recommendation. If no recommendation is present, use starting block address that is a multiple of 8KB</td>
                        <td>Align Partition</td>
                    </tr>
                    <tr>
                        <td>
                            SIOC
                        </td>
                        <td>
                            Enables datastore resource sharing among VMS. Can be benefitial when there are many VMs sharing a single datastore.
                        </td>
                        <td>
                            vSphere Client -> Datastore -> Configuration -> Properties -> SIOC -> Enable
                        </td>
                        <td>
                            Enable when VM / datastore ratio is high
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Jumbo Frames
                        </td>
                        <td>
                            MTU > 1500 is Jumbo. Enable Jumbo Frames to reduce CPU processing overhead with iSCSI (SW/HW). End to end support and enabling is required. On vSphere, Enable Jumbo Frames in virtual switches (SWiSCSI) and storage adapter (HWiSCSI)
                        </td>
                        <td>
                            Manage -> Networking -> Virtual Switches -> Settings -> Properties -> MTU;
                            Manage -> Storage -> Storage Adapters -> Advanced Options -> Edit -> MTU
                        </td>
                        <td>
                            Enable Jumbo Frames End to End
                        </td>
                    </tr>
                    <tr>
                        <td>
                            VLAN
                        </td>
                        <td>
                            Create VLAN for vmknic and iSCSI/NFS Server. Having separate VLAN helps reduce network interference
                        </td>
                        <td>

                        </td>
                        <td>
                            Create VLAN
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Keep VMs/LUNs ratio low
                        </td>
                        <td>
                            Provisioning more LUNs and keeping the VMs on these LUNs low helps present I/Os simultaneously to the array increasing performance. Use ESXTOP to monitor Device latencies and provision accordingly.
                        </td>
                        <td>
                            Follow storage vendor recommendations
                        </td>
                        <td>
                            Provision more LUNs for spreading the I/O load.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Use ESXTOP
                        </td>
                        <td>
                            esxtop can be used to troubleshoot storage performance problems. It provides a starting point to root cause a storage performance issue
                        </td>
                        <td>
                            Use vSphere kb article No 1008205
                            Use Yellow Bricks ESXTOP article <a href='http://www.yellow-bricks.com/esxtop/'>Yellow Bricks</a>
                        </td>
                        <td>
                            Use esxtop for troubleshooting storage issues
                        </td>
                    </tr>
                    <tr>
                        <td>
                            vHBA reqCallThreshold
                        </td>
                        <td>
                            If using LSILogic vHBA or PVSCSI vHBA for VMs, you can set a lower threshold value. If set to 1, even if there is 1 I/O in the vHBA layer, it will be dispatched to the lower layer
                        </td>
                        <td>
                            esxcfg-advcfg -s X /Disk/ReqCallThreshold
                            You can also set this in a vmx file using the following command
                            scsiY.reqCallThreshold = X (where Y is the target SCSI number and X is the desired reqCallThreshold value
                        </td>
                        <td>
                            Lower the reqCallThreshold for latency sensitive applications
                        </td>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 55 storage content -->
                Sources:
            </div>
            <div id=vsphere55network>
                <table class=table55 id=table55network>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td></td>
                        <td></td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 55 network content -->
            </div>
            <div id=vsphere55general>
                <table class=table55 id=table55general>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td></td>
                        <td></td>
                        <td></td>
                        <td></td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 55 general content -->
            </div>
        </div>
        <div class='centos' id=hyper3>
            <div id=centoshardware>
                <table class=table60 id=table60hardware>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Intel VT-x or AMD-V</td>
                        <td>Hardware assisted CPU virtualization assistance</td>
                        <td>Reboot host, Enter BIOS, Enable VT-x or AMD-V</td>
                        <td>Enable</td>
                    </tr>
                    <tr>

                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 hardware content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=centosstorage>
                <table class=tablecentos id=tablecentosstorage>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>
                            Increase Block Device Queue Depth
                        </td>
                        <td>
                            Increase device queue depth if there is a lot of queueing
                        </td>
                        <td>
                            echo 256 > /sys/block/sdX/queue/nr_requests
                            echo 128 > /sys/block/sdY/device/queue_depth
                        </td>
                        <td>
                            128
                        </td>
                    </tr>
                    </table>
                <!-- ToDo, add vsphere 60 storage content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=centosnetwork>
                <table class=tablecentos id=tablecentosnetwork>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Net.TcpipHeapMax</td>
                        <td></td>
                        <td>esxcfg-advcfg /Net/TcpipHeapMax -s 1536</td>
                        <td>1536</td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 network content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
            <div id=centosgeneral>
                <table class=tablecentos id=tablecentosgeneral>
                    <tr>
                        <th>Option</th>
                        <th>Description</th>
                        <th>How to set</th>
                        <th>Recommended value</th>
                    </tr>
                    <tr>
                        <td>Net.TcpipHeapMax</td>
                        <td>Max heap that can be used for TCP IP. Benefits when number of NFS luns is high. Size in MB</td>
                        <td></td>
                        <td>1536</td>
                    </tr>
                    <tr>
                    </tr>
                </table>
                <!-- ToDo, add vsphere 60 general content -->
                Sources:
                <a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/vmware-perfbest-practices-vsphere6-0-white-paper.pdf">vSphere 6.0 Performance Best Practice Guide</a>
            </div>
        </div>
    </div>
    <script>
    function selectArea(areas, platform){
        document.getElementById('vsphere60storage').style.display = 'none';
        document.getElementById('vsphere60network').style.display = 'none';
        document.getElementById('vsphere60general').style.display = 'none';
        document.getElementById('vsphere60hardware').style.display = 'none';
        document.getElementById('vsphere55storage').style.display = 'none';
        document.getElementById('vsphere55network').style.display = 'none';
        document.getElementById('vsphere55general').style.display = 'none';
        document.getElementById('vsphere55hardware').style.display = 'none';
        document.getElementById('centosstorage').style.display = 'none';
        document.getElementById('centosnetwork').style.display = 'none';
        document.getElementById('centosgeneral').style.display = 'none';
        document.getElementById('centoshardware').style.display = 'none';
        if (platform == 'vsphere60'){
            if (areas == 'storage'){
                document.getElementById('vsphere60storage').style.display = 'block';
            }
            else if (areas == 'network'){
                document.getElementById('vsphere60network').style.display = 'block';
            }
            else if (areas == 'general'){
                document.getElementById('vsphere60general').style.display = 'block';
            }
            else if (areas == 'hardware'){
                document.getElementById('vsphere60hardware').style.display = 'block';
            }
        }
        else if (platform == 'vsphere55'){
            if (areas == 'storage'){
                document.getElementById('vsphere55storage').style.display = 'block';
            }
            else if (areas == 'network'){
                document.getElementById('vsphere55network').style.display = 'block';
            }
            else if (areas == 'general'){
                document.getElementById('vsphere55general').style.display = 'block';
            }
            else if (areas == 'hardware'){
                document.getElementById('vsphere55hardware').style.display = 'block';
            }
        }
        else if (platform == 'centos'){
            if (areas == 'storage'){
                document.getElementById('centosstorage').style.display = 'block';
            }
            else if (areas == 'network'){
                document.getElementById('centosnetwork').style.display = 'block';
            }
            else if (areas == 'general'){
                document.getElementById('centosgeneral').style.display = 'block';
            }
            else if (areas == 'hardware'){
                document.getElementById('centoshardware').style.display = 'block';
            }
        }
    }
    </script>
</body>
</html>
